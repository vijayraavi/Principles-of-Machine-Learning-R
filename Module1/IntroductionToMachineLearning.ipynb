{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "\n",
    "This lab introduces some basic concepts of machine learning with R. In this lab you will use the K-Nearest Neighbor (KNN) algorithm to classify the species of iris flowers, given measurements of flower characteristics. By completing this lab you will have an overview of an end-to-end machine learning modeling process.  \n",
    "\n",
    "By the completion of this lab, you will:\n",
    "1. Follow and understand a complete end-to-end machine learning process including data exploration, data preparation, modeling, and model evaluation. \n",
    "2. Develop a basic understanding of the principles of machine learning and associated terminology. \n",
    "3. Understand the basic process for evaluating machine learning models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of KNN classification\n",
    "\n",
    "Before discussing a specific algorithm, it helps to know a bit of machine learning terminology. In supervised machine learning a set of ***cases*** are used to ***train***, ***test*** and ***evaluate*** the model. Each case is comprised of the values of one or more ***features*** and a ***label*** value. The features are variables used by the model to ***predict** the value of the label. Minimizing the ***errors*** between the true value of the label and the prediction supervises the training of this model. Once the model is trained and tested, it can be evaluated based on the accuracy in predicting the label of a new set of cases. \n",
    "\n",
    "In this lab you will use randomly selected cases to first train and then evaluate a k-nearest-neighbor (KNN) machine learning model. The goal is to predict the type or class of the label, which makes the machine learning model a ***classification*** model. \n",
    "\n",
    "The k-nearest-neighbor algorithm is conceptually simple. In fact, there is no formal training step. Given a known set of cases, a new case is classified by majority vote of the K (where $k = 1, 2, 3$, etc.) points nearest to the values of the new case; that is, the nearest neighbors of the new case. \n",
    "\n",
    "The schematic figure below illustrates the basic concepts of a KNN classifier. In this case there are two features, the values of one shown on the horizontal axis and the values of the other shown on the vertical axis. The cases are shown on the diagram as one of two classes, red triangles and blue circles. To summarize, each case has a value for the two features, and a class. The goal of thee KNN algorithm is to classify cases with unknown labels. \n",
    "\n",
    "Continuing with the example, on the left side of the diagram the $K = 1$ case is illustrated. The nearest neighbor is a red triangle. Therefore, this KNN algorithm will classify the unknown case, '?', as a red triangle. On the right side of the diagram, the $K = 3$ case is illustrated. There are three near neighbors within the circle. The majority of nearest neighbors for $K = 3$ are the blue circles, so the algorithm classifies the unknown case, '?', as a blue circle. Notice that class predicted for the unknown case changes as K changes. This behavior is inherent in the KNN method.  \n",
    "\n",
    "![](img/KNN.jpg)\n",
    "<center> **KNN for k = 1 and k = 3**</center>\n",
    "\n",
    "There are some additional considerations in creating a robust KNN algorithm. These will be addressed later in this course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the data set\n",
    "\n",
    "In this lab you will work with the Iris data set. This data set is famous in the history of statistics. The first publication using these data in statistics by the pioneering statistician Ronald A Fisher was in his 1936. Fisher proposed an algorithm to classify the species of iris flowers from physical measurements of their characteristics. The data set has been used as a teaching example ever since. \n",
    "\n",
    "Now, you will load and examine these data. Execute the code in the cell below and examine the first few rows of the data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data(iris) # Load the iris data set\n",
    "head(iris) # look at the first few rows of the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four features, containing the dimensions of parts of the iris flower structures. The label column is the Species of the flower. The goal is to create and test a KNN algorithm to correctly classify the species. \n",
    "\n",
    "Next, you will execute the code in the cell below to show the data types of each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features are all numeric, and the label is of categorical or Factor type.\n",
    "\n",
    "Next, you will determine the number of unique categories, and number of cases for each category, for the label variable, Species. Execute the code in the cell below and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(iris$Species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see there are three species of iris, each with 50 cases. \n",
    "\n",
    "Next, you will create some plots to see how the classes might, or might not, be well separated by the value of the features. In an idea case, the label classes will be perfectly separated by one or more of the feature pairs. In the real-world this ideal situation will rarely, if ever, be the case.\n",
    " \n",
    "There are six possible pair-wise scatter plots of these four features. For now, we will just create scatter plots of two variable pairs. Execute the code in the cell below and examine the resulting plots.\n",
    "***\n",
    "**Note:** Data visualization and the ggplot2 package are covered in another lesson.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(repr)\n",
    "options(repr.plot.width=5, repr.plot.height=4) # Set the initial plot area dimensions\n",
    "\n",
    "ggplot(iris, aes(Sepal.Width, Sepal.Length)) + geom_point(aes(color = Species))\n",
    "ggplot(iris, aes(Petal.Width, Sepal.Length)) + geom_point(aes(color = Species))                                                                                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these results noticing the separation, or overlap, of the label values.\n",
    "\n",
    "Then, answer **Question 1** on the course page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data set\n",
    "\n",
    "Data preparation is an important step before training any machine learning model. These data require only two preparation steps:\n",
    "- Scale the numeric values of the features. It is important that numeric features used to train machine learning models have a similar range of values. Otherwise, features which happen to have large numeric values may dominate model training, even if other features with smaller numeric values are more informative. In this case Zscore normalization is used. This normalization process scales each feature so that the mean is 0 and the variance is 1.0. \n",
    "- Split the dataset into randomly sampled training and evaluation data sets. The random selection of cases seeks to limit the leakage of information between the training and evaluation cases.\n",
    "\n",
    "The code in the cell below iterates over the numeric feature columns of the data frame. A statistical summary of the data frame is then printed. Execute this code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[,c('Sepal.Width', 'Sepal.Length', 'Petal.Width', 'Petal.Length')] = \n",
    "    lapply(iris[,c('Sepal.Width', 'Sepal.Length', 'Petal.Width', 'Petal.Length')], scale)\n",
    "print(summary(iris))\n",
    "print(sapply(iris[,c('Sepal.Width', 'Sepal.Length', 'Petal.Width', 'Petal.Length')], sd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these results. The mean is zero and the variance approximately 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will split the dataset into a test and evaluation sub-sets. The code in the cell below randomly samples the cases and places them in either the training or test data frame. Execute this code to create these subsets. \n",
    "\n",
    "***\n",
    "**Note:** The use of the dplyr package and other packages in the Tidyverse for data preparation is covered in other labs and courses.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into a training and test set by Bernoulli sampling\n",
    "library(dplyr)\n",
    "set.seed(2345)\n",
    "train.iris = sample_frac(iris, 0.7)\n",
    "test.iris = iris[-as.numeric(rownames(train.iris)),] # use as.numeric because rownames() returns character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the KNN model\n",
    "\n",
    "With some understanding of the relationships between the features and the label and preparation of the data completed you will now train and evaluate a $K = 3$ model. The code in the cell below does the following:\n",
    "- Defines the model in the R modeling language as $Species \\sim\\ .$. In English this formula means model the label Species by all of the other columns (features) in the data frame, indicated by $.$. \n",
    "- Sets the training data set to the subset created above. \n",
    "- Sets the test data set to the subset created above. The performance of the model is evaluated on thee prediction accuracy on the labels of this subset.\n",
    "- The the value of K at 3.\n",
    "- Prints the summary of the model. \n",
    "\n",
    "Execute this code and examine the summary of these results.\n",
    "\n",
    "\n",
    "***\n",
    "**Note:** Additional information on defining models with the R modeling language is in another lesson.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Compute a k = 3 nearest neighbor model\n",
    "library(kknn)\n",
    "knn.3 <- kknn(Species ~ ., train = train.iris, test = test.iris, k=3)\n",
    "summary(knn.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the summary of the model and notice the following:\n",
    "- A summary of the model is displayed. \n",
    "- The classification results for the test data are displayed. You can see the most probable class along with the probabilities of the prediction for each class. The most probable class is the prediction. \n",
    "\n",
    "Next, execute the code in the cell below to compute the accuracy of the model. Accuracy is the percentage of the test cases correctly classified. Execute this code, examine the results, and answer **Question 2** on the course page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iris$predicted = predict(knn.3)\n",
    "test.iris$correct = test.iris$Species == test.iris$predicted\n",
    "round(100 * sum(test.iris$correct) / nrow(test.iris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, execute the code in the cell below and examine plots of the classifications of the iris species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ggplot(test.iris, aes(Sepal.Width, Sepal.Length)) + geom_point(aes(color = predicted, shape = correct))\n",
    "ggplot(test.iris, aes(Petal.Width, Sepal.Length)) + geom_point(aes(color = predicted, shape = correct))                                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the plots above color is used to show the predicted class. Correctly classified cases are shown by triangles and incorrectly classified cases are shown by circles. \n",
    "\n",
    "Examine the plot and answer **Question 3** on the course page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab you have created and evaluated a KNN machine learning classification model. Specifically you have:\n",
    "1. Loaded and explored the data using visualization to determine if the features separate the classes.\n",
    "2. Prepared the data by normalizing the numeric features and randomly sampling into training and testing subsets. \n",
    "3. Constructing and evaluating the machine learning model. Evaluation was performed by statistically, with the accuracy metric, and with visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
